{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100% local Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys # New import for recursion limit\n",
    "import warnings\n",
    "from crewai import Agent, Crew, Task, LLM, Process\n",
    "from src.agentic_rag.tool.custom_tool import DocumentSearchTool\n",
    "from src.agentic_rag.tool.custom_tool import FireCrawlWebSearchTool\n",
    "from crewai_tools import SerperDevTool # NEW: Import SerperDevTool\n",
    "from dotenv import load_dotenv # NEW: Import for loading .env variables\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# NEW: Increase the recursion limit for stability\n",
    "# This helps prevent recursion errors from deep call stacks, especially with verbose logging.\n",
    "sys.setrecursionlimit(5000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Setup LLM\n",
    "\n",
    "# %%\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# --- LLM Configuration for OpenAI ---\n",
    "# Ensure you have 'langchain-openai' installed: pip install langchain-openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM using ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  # Gets your OpenAI API key from .env\n",
    "    model=\"gpt-4o\",                       # Recommended: gpt-4o for best performance. You can also try \"gpt-4-turbo\" or \"gpt-3.5-turbo\"\n",
    "    temperature=0.7                       # Good default for balanced creativity/accuracy\n",
    ")\n",
    "\n",
    "# IMPORTANT: Remove or comment out any previous Groq-specific environment variable settings\n",
    "# that might still be present and causing conflicts, for example:\n",
    "# # os.environ[\"OPENAI_API_BASE\"] = \"https://api.groq.com/openai/v1\"\n",
    "# # os.environ[\"OPENAI_MODEL_NAME\"] = os.getenv(\"MODEL\")\n",
    "# # os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"GROQ_API_KEY\") # This mapping is for Groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Setup Tools\n",
    "\n",
    "# Robust PDF path calculation for Jupyter Notebooks\n",
    "# This assumes the notebook is being run with the project's root directory (AGENTIC_RAG/)\n",
    "# as the current working directory of the Jupyter kernel.\n",
    "project_root_dir = os.getcwd()\n",
    "pdf_file_path = os.path.join(project_root_dir, \"knowledge\", \"dspy.pdf\")\n",
    "\n",
    "# If for some reason the notebook's working directory is AGENTIC_RAG/src/agentic_rag/\n",
    "# and your project root is AGENTIC_RAG/, you would need this instead:\n",
    "# pdf_file_path = os.path.join(project_root_dir, \"..\", \"..\", \"knowledge\", \"dspy.pdf\")\n",
    "# However, the first option (assuming project root is CWD) is more common in well-set-up VS Code workspaces.\n",
    "\n",
    "\n",
    "# Initialize your custom DocumentSearchTool\n",
    "pdf_tool = DocumentSearchTool(file_path=pdf_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the API key for FireCrawl in your environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: Initialize SerperDevTool for general web search queries\n",
    "web_search_tool_serper = SerperDevTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your custom FireCrawlWebSearchTool for URL scraping\n",
    "# Note: This tool's description should clearly state it expects a URL in custom_tool.py\n",
    "firecrawl_web_search_tool = FireCrawlWebSearchTool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agents\n",
    "\n",
    "# %%\n",
    "retriever_agent = Agent(\n",
    "    role=\"\"\"Retrieve relevant information to answer the user query: {query}\"\"\",\n",
    "    # UPDATED GOAL: Explicitly mentions Serper for general web search and FireCrawl for URL scraping.\n",
    "    goal=\"\"\"Retrieve the most relevant information from the available sources for the user query: {query}.\n",
    "            First, **always** attempt to find information using the 'DocumentSearchTool' in the provided PDF knowledge base.\n",
    "            If the information is not found or is incomplete in the PDF, then use the 'SerperDevTool' for a general web search\n",
    "            to find up-to-date and relevant information.\n",
    "            If the 'SerperDevTool' provides a specific URL that looks highly relevant, consider using the 'FireCrawlWebSearchTool'\n",
    "            to scrape the content from that specific URL for detailed extraction.\n",
    "            Your final output should be the most relevant information in text format.\"\"\",\n",
    "    backstory=\"\"\"You're a meticulous analyst with a keen eye for detail.\n",
    "                You're known for your ability to understand the user query: {query}\n",
    "                and retrieve knowledge from the most suitable knowledge base,\n",
    "                prioritizing internal documents then web search,\n",
    "                and then detailed web content extraction if a URL is available.\"\"\",\n",
    "    verbose=False,\n",
    "    tools=[\n",
    "        pdf_tool,\n",
    "        web_search_tool_serper, # IMPORTANT: This is for general web search\n",
    "        firecrawl_web_search_tool # IMPORTANT: This is for scraping specific URLs found by Serper\n",
    "    ],\n",
    "    allow_delegation=False, # NEW: Prevent unintended delegation\n",
    "    max_iterations=20, # NEW: Set a maximum number of steps for the agent\n",
    "    llm=llm # Explicitly pass the LLM object to the agent\n",
    ")\n",
    "\n",
    "response_synthesizer_agent = Agent(\n",
    "    role=\"\"\"Response synthesizer agent for the user query: {query}\"\"\",\n",
    "    goal=\"\"\"Synthesize the retrieved information into a concise and coherent response\n",
    "            based on the user query: {query}. If you are not able to retrieve the\n",
    "            information (e.g., from the previous agent), then respond with\n",
    "            \"I'm sorry, I couldn't find the information you're looking for.\" \"\"\",\n",
    "    backstory=\"\"\"You're a skilled communicator with a knack for turning complex\n",
    "                information into clear and concise responses.\"\"\",\n",
    "    verbose=False,\n",
    "    allow_delegation=False, # NEW: Prevent unintended delegation\n",
    "    max_iterations=10, # NEW: Set a maximum number of steps for the agent\n",
    "    llm=llm # Explicitly pass the LLM object to the agent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tasks\n",
    "\n",
    "# %%\n",
    "retrieval_task = Task(\n",
    "    description=\"\"\"Retrieve the most relevant information from the available\n",
    "                   sources for the user query: {query}\"\"\",\n",
    "    expected_output=\"\"\"The most relevant information in form of text as retrieved\n",
    "                       from the sources.\"\"\",\n",
    "    agent=retriever_agent\n",
    ")\n",
    "\n",
    "response_task = Task(\n",
    "    description=\"\"\"Synthesize the final response for the user query: {query}\"\"\",\n",
    "    expected_output=\"\"\"A concise and coherent response based on the retrieved information\n",
    "                       from the right source for the user query: {query}. If you are not\n",
    "                       able to retrieve the information then respond with\n",
    "                       I'm sorry, I couldn't find the information you're looking for.\"\"\",\n",
    "    agent=response_synthesizer_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize Crew\n",
    "\n",
    "# %%\n",
    "crew = Crew(\n",
    "            agents=[retriever_agent, response_synthesizer_agent],\n",
    "            tasks=[retrieval_task, response_task],\n",
    "            process=Process.sequential,\n",
    "            verbose=False, # NEW: Set verbose to 2 for more detailed logs\n",
    "            # process=Process.hierarchical, # In case you wanna use that instead https://docs.crewai.com/how-to/Hierarchical/\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kickoff Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2025 Australian Open is scheduled to be a Grand Slam level tennis tournament held at Melbourne Park from January 12 to January 26, 2025. It will be the 113th edition of the Australian Open, the 57th in the Open Era, and the first major of the year.\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={\"query\": \"When is Australian open 2025 happening?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
